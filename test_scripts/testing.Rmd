---
title: "Testing the file read"
output: 
  html_document:
    df_print: paged
    toc: yes
    toc_float: true
    toc_depth: 3
    code_folding: show
editor_options: 
  chunk_output_type: console
---

```{r setup}
library(tidyverse)
library(stringr)
library(readxl)
library(knitr)
library(broom)
library(modelr)
library(plotly)
library(glue)
knitr::opts_knit$set(root.dir = "..") 
```


```{r}
devtools::load_all(".")
filepath <- file.path("tests", "testthat", "test_data", "svm_pred_results.csv")
svm_data <- read_svm_data_file(filepath)
metadata <- read_excel(file.path("test_scripts", "metadata.xlsx"))
kable(metadata, d=2)
```



```{r}
svm_data_filtered <- 
  svm_data %>% 
  # turnover function
  rename_proteins(file.path("tests", "testthat", "test_data", "rename_prot.xlsx")) %>% 
  # turnover function
  filter_peptides_by_spectral_fit(pred_cutoff = 0.75) %>% 
  # turnover function
  calculate_fraculab() %>% 
  # adjust names (not a turnover function)
  select(unishort = uniShort, protein = prot, gene, isopep = seqz, sample, frac_ulab, frac_lab) %>% 
  # turnover function
  #filter_min_timepoints(min_timepoint_present = 3) %>% 
  # add metatdata to get times for samples - should this be a turnover function?
  left_join(metadata, by = "sample")
```

```{r}
devtools::load_all()
final_data <- calculate_label_rate(svm_data_filtered, quiet = FALSE) %>% 
  filter(enough_data, !fit_error) %>% 
  select(-enough_data, -fit_error) %>% 
  calculate_degrate_dissipation(0.066)
```


```{r, fig.width = 8, fig.height=7}
# plot estimates vs their residual standard error (+ the error of the estimate itself)
svm_data_rates %>%
  ggplot() +
  aes(x = label_rate, y = 100*fit_rse, color = factor(num_datapoints)) +
  geom_errorbarh(map = aes(xmin = label_rate - label_rate_se, xmax = label_rate + label_rate_se)) +
  geom_point() +
  #theme(legend.position = "none") + 
  labs(y = "residual standard error (% labelled)", x = "d estimate")
ggplotly()
```

# What do the different residual standard error ranges look like?

Note: resid. SE would look different if tp=0 were not included in the fit (i.e. assuming tp 0 would always be 0% labeled and any measurements that indicates not 0 tp would not be relevant)

```{r fig.width = 10, fig.height=10}
# we shoudl include something like this with the curves
se_groups <- c(1, 2.5, 5, 7.5, 10, 15, 20, 25, 30)

# plot data based on standard error to get a sense for cutoffs
p <- svm_models %>%
  filter(!nls_error) %>%
  mutate(
    nls_resid_se = 100*map_dbl(nls_summary, ~.x$sigma),
    se_group = map_dbl(nls_resid_se, ~sum(.x > se_groups) + 1),
    se_group_name = map_dbl(se_group, ~se_groups[.x])
  ) %>%
  arrange(se_group, desc(nls_resid_se)) %>% 
  group_by(se_group) %>% mutate(se_group_nr = 1:n()) %>% ungroup() %>% 
  # select up to 3 in each group
  filter(se_group_nr <= 3) %>% 
  #filter(nls_resid_se > 15) %>%
  # NOTE: select random set of curves in different intervals of resid.SE
  # randomly select 9 curves
  arrange(nls_resid_se) %>% 
  mutate(panel = forcats::as_factor(paste("resid. SE [% labeled] about", se_group_name))) %>% 
  # calculate curves
  mutate(
    nls_fit_curve = map2(data, nls_fit, ~data_grid(.x, hours = seq_range(hours, 20)) %>%
                           add_predictions(.y, var = "frac_lab"))
  ) %>%
  # plot
  ggplot() +
  aes(x = hours, y = frac_lab, color = protein, group = isopep, label = nls_resid_se) +
  geom_line(data = function(x) unnest(x, nls_fit_curve)) +
  geom_line(data = function(x) unnest(x, data), linetype = 2) +
  geom_point(data = function(x) unnest(x, data)) +
  facet_wrap(~panel)
ggplotly(p)
```

